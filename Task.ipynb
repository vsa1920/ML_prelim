{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOb8941OI1BTFYFmqKY6MO1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsa1920/ML_prelim/blob/main/Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFVkDHZPjdmH"
      },
      "source": [
        "# Run before executing the code\n",
        "#!pip install spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install spektral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYYrFXVjkTdj"
      },
      "source": [
        "# Spacy for generating word embeddings for the node features of GNN\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo44X9zex3_Q"
      },
      "source": [
        "# Hyperparameters\n",
        "P = 4 # Window Size for Words while generating graphs\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "epochs = 40"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZjBYM-hxSF"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from spektral.data import Graph, Dataset, DisjointLoader\n",
        "from spektral.models import GeneralGNN"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg02Pb2dxK-V"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.backend import argmax"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1s6M-VOIWb4"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q95xrce2oB11"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/vsa1920/ML_prelim/main/train.csv\")\n",
        "data.dropna(axis=0, inplace=True)\n",
        "num_tags = len(data[\"Industry Classification Tag\"].unique())\n",
        "# Look at all the unique tags in the dataset - These will be our targets\n",
        "labels = {data[\"Industry Classification Tag\"].unique()[i]:i for i in range(num_tags)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDAiCOOEyaA3"
      },
      "source": [
        "def text_to_graph(text, label):\n",
        "  \"\"\"\n",
        "  Generates a graph from text (Business Description)\n",
        "  The node features are taken to be the word vector embeddings\n",
        "  \"\"\"\n",
        "  line_embedding = nlp(text.lower())\n",
        "  #token_size = len(line_embedding[0].vector)\n",
        "  n = len(line_embedding)\n",
        "  x = np.array([token.vector for token in line_embedding])\n",
        "  a = np.zeros((n, n))\n",
        "  for i in range(n):\n",
        "    for j in range(max(0, i-P), min(n, i+P)):\n",
        "      a[i][j] = 1\n",
        "    a[i][i] = 0\n",
        "  y = np.zeros(len(labels))\n",
        "  y[labels[label]] = 1\n",
        "  return Graph(x=x, a=sp.csr_matrix(a), y=y)\n",
        "\n",
        "def sample_to_graph(text):\n",
        "  \"\"\"\n",
        "  Generates a graph from text (Business Description)\n",
        "  The node features are taken to be the word vector embeddings\n",
        "  This function is to generate a sample of graphs for prediction with no targets\n",
        "  \"\"\"\n",
        "  line_embedding = nlp(text.lower())\n",
        "  #token_size = len(line_embedding[0].vector)\n",
        "  n = len(line_embedding)\n",
        "  x = np.array([token.vector for token in line_embedding])\n",
        "  a = np.zeros((n, n))\n",
        "  for i in range(n):\n",
        "    for j in range(max(0, i-P), min(n, i+P)):\n",
        "      a[i][j] = 1\n",
        "    a[i][i] = 0\n",
        "  y = np.zeros(62)\n",
        "  return Graph(x=x, a=sp.csr_matrix(a), y=y)   "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzzg7ZnpyeBP"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  \"\"\"\n",
        "  A dataset of graphs created from the Business Description using text_to_graph method.\n",
        "  \"\"\"\n",
        "  def __init__(self, pd_dataframe, **kwargs):\n",
        "    self.dataframe = pd_dataframe\n",
        "    super().__init__(**kwargs)\n",
        "    \n",
        "  def read(self):\n",
        "    graph_list = []\n",
        "    for row_idx in range(len(self.dataframe)):\n",
        "      graph_list.append(text_to_graph(self.dataframe.iloc[row_idx][\"Business Description\"], self.dataframe.iloc[row_idx][\"Industry Classification Tag\"]))\n",
        "    return graph_list\n",
        "\n",
        "# The following class is to make a dataset where the targets are not known\n",
        "class SampleDataset(Dataset):\n",
        "  \"\"\"\n",
        "  A dataset of graphs created from the Business Description using text_to_graph method.\n",
        "  \"\"\"\n",
        "  def __init__(self, pd_dataframe, **kwargs):\n",
        "    self.dataframe = pd_dataframe\n",
        "    super().__init__(**kwargs)\n",
        "    \n",
        "  def read(self):\n",
        "    graph_list = []\n",
        "    for row_idx in range(len(self.dataframe)):\n",
        "      graph_list.append(sample_to_graph(self.dataframe.iloc[row_idx][\"Business Description\"]))\n",
        "    return graph_list"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_rGkEicidNS"
      },
      "source": [
        "# This creates a dataset of graphs with node features as word vector embeddings\n",
        "dataset = MyDataset(data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leYIHABNl8-Z"
      },
      "source": [
        "# Fitting a General GNN Model - Better architecture can be used\n",
        "# Dropout was tuned with validation set to avoid overfitting\n",
        "model = GeneralGNN(len(labels), activation='softmax', dropout=0.3)\n",
        "optimizer = Adam(learning_rate)\n",
        "loss_fn = CategoricalCrossentropy()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwu7LDUCwSYD"
      },
      "source": [
        "# Code used from Spektral examples to fit a general GNN Model\n",
        "# Train/validation split\n",
        "np.random.shuffle(dataset)\n",
        "split = int(0.8 * len(dataset))\n",
        "data_tr, data_te = dataset[:split], dataset[split:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "561NXHCUxiIM"
      },
      "source": [
        "# Data loader\n",
        "loader_tr = DisjointLoader(data_tr, batch_size=batch_size, epochs=epochs)\n",
        "loader_te = DisjointLoader(data_te, batch_size=len(data_te))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWjHLrT7yEEc"
      },
      "source": [
        "# Training function\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_on_batch(inputs, target):\n",
        "    \"\"\"\n",
        "    A method to use loaders to train the GNN on -\n",
        "    Loaders are responsible for handling data in batches and monitoring their performance\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(target, predictions) + sum(model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    acc = tf.reduce_mean(categorical_accuracy(target, predictions))\n",
        "    return loss, acc"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mojvq0AIybdZ"
      },
      "source": [
        "# Evaluation function\n",
        "def evaluate(loader):\n",
        "    \"\"\"\n",
        "    Method to evaluate performance from the validation set generated from the samples\n",
        "    \"\"\"\n",
        "    step = 0\n",
        "    results = []\n",
        "    for batch in loader:\n",
        "        step += 1\n",
        "        inputs, target = batch\n",
        "        predictions = model(inputs, training=False)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        acc = tf.reduce_mean(categorical_accuracy(target, predictions))\n",
        "        # Convert the one-hot results into \n",
        "        truth, preds = argmax(target, axis=-1).numpy(), argmax(predictions, axis=-1).numpy()\n",
        "        results.append((loss, acc, len(target)))  # Keep track of batch size\n",
        "        if step == loader.steps_per_epoch:\n",
        "            results = np.array(results)\n",
        "            print (classification_report(truth, preds, zero_division = 0))\n",
        "            return np.average(results[:, :-1], 0, weights=results[:, -1])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl6afgWwylst",
        "outputId": "8e663813-7802-4950-a04a-3ccd33858c2e"
      },
      "source": [
        "# Training loop\n",
        "epoch = step = 0\n",
        "results = []\n",
        "for batch in loader_tr:\n",
        "    step += 1\n",
        "    loss, acc = train_on_batch(*batch)\n",
        "    results.append((loss, acc))\n",
        "    if step == loader_tr.steps_per_epoch:\n",
        "        step = 0\n",
        "        epoch += 1\n",
        "        results_te = evaluate(loader_te)\n",
        "        print(\n",
        "            \"Epoch {} - Train loss: {:.3f} - Train acc: {:.3f} - \"\n",
        "            \"Test loss: {:.3f} - Test acc: {:.3f}\".format(\n",
        "                epoch, *np.mean(results, 0), *results_te\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.62      0.70        24\n",
            "           1       0.80      0.31      0.44        13\n",
            "           2       1.00      0.50      0.67         8\n",
            "           3       0.64      0.84      0.73        19\n",
            "           4       0.62      0.43      0.51        35\n",
            "           5       0.59      0.67      0.63        24\n",
            "           6       0.80      0.67      0.73        12\n",
            "           7       0.64      0.78      0.71        86\n",
            "           8       0.64      0.67      0.65        24\n",
            "           9       0.88      1.00      0.93        21\n",
            "          10       0.17      0.60      0.27        15\n",
            "          11       1.00      0.22      0.36         9\n",
            "          12       1.00      0.46      0.63        13\n",
            "          13       0.48      0.67      0.56        15\n",
            "          14       0.43      0.64      0.51        14\n",
            "          15       1.00      0.12      0.22        16\n",
            "          16       0.17      0.56      0.26         9\n",
            "          17       1.00      0.08      0.14        13\n",
            "          18       0.80      0.80      0.80        15\n",
            "          19       0.50      0.57      0.53        14\n",
            "          20       0.57      0.24      0.33        17\n",
            "          21       0.57      0.47      0.52        17\n",
            "          22       0.97      0.71      0.82        80\n",
            "          23       0.30      0.84      0.44        37\n",
            "          24       1.00      0.73      0.84        11\n",
            "          25       0.45      0.29      0.36        17\n",
            "          26       0.24      0.44      0.31         9\n",
            "          27       0.00      0.00      0.00         7\n",
            "          28       0.83      0.67      0.74        15\n",
            "          29       0.54      1.00      0.70         7\n",
            "          30       1.00      0.17      0.29        12\n",
            "          31       0.43      0.14      0.21        21\n",
            "          32       0.86      0.46      0.60        13\n",
            "          33       0.40      0.12      0.19        16\n",
            "          34       0.00      0.00      0.00        11\n",
            "          35       1.00      0.08      0.14        13\n",
            "          36       1.00      0.33      0.50         9\n",
            "          37       0.00      0.00      0.00        14\n",
            "          38       0.26      0.83      0.40         6\n",
            "          39       0.27      0.15      0.19        20\n",
            "          40       0.30      0.94      0.45        16\n",
            "          41       1.00      0.67      0.80        18\n",
            "          42       0.84      0.84      0.84        45\n",
            "          43       0.22      1.00      0.36         5\n",
            "          44       1.00      0.09      0.17        11\n",
            "          45       0.60      0.75      0.67         4\n",
            "          46       0.35      0.64      0.45        14\n",
            "          47       0.40      0.47      0.43        38\n",
            "          48       0.89      0.80      0.84        10\n",
            "          49       0.88      0.64      0.74        11\n",
            "          50       0.93      0.65      0.77       118\n",
            "          51       0.53      0.39      0.45        23\n",
            "          52       1.00      0.73      0.85        15\n",
            "          53       0.50      0.54      0.52        13\n",
            "          54       0.27      0.60      0.37        10\n",
            "          55       0.29      0.20      0.24        10\n",
            "          56       0.78      0.41      0.54        17\n",
            "          57       0.36      0.50      0.42        10\n",
            "          58       0.50      0.11      0.18         9\n",
            "          59       0.00      0.00      0.00        23\n",
            "          60       0.37      1.00      0.54        25\n",
            "          61       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.56      1205\n",
            "   macro avg       0.59      0.50      0.47      1205\n",
            "weighted avg       0.65      0.56      0.55      1205\n",
            "\n",
            "Epoch 1 - Train loss: 1.500 - Train acc: 0.616 - Test loss: 1.832 - Test acc: 0.557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXUmFXBLy1Ys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "78dec849-8094-4734-bd21-7e6fb780b07d"
      },
      "source": [
        "# Read the test files\n",
        "sample_set = pd.read_csv(\"https://raw.githubusercontent.com/vsa1920/ML_prelim/main/test.csv\")\n",
        "sample_set[\"Industry Classification Tags\"] = np.nan\n",
        "sample_set.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Business Description</th>\n",
              "      <th>Industry Classification Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3rd Rock Multimedia Ltd</td>\n",
              "      <td>3rd Rock Multimedia Limited is an India-based ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Andhra Petrochemicals Ltd</td>\n",
              "      <td>The Andhra Petrochemicals Limited is an India-...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Force Motors Ltd</td>\n",
              "      <td>Force Motors Limited is a holding company. The...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Diamines And Chemicals Ltd</td>\n",
              "      <td>Diamines and Chemicals Limited is a holding co...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Insilco Ltd</td>\n",
              "      <td>Insilco Limited is engaged in manufacturing an...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Company   ... Industry Classification Tags\n",
              "0     3rd Rock Multimedia Ltd  ...                          NaN\n",
              "1   Andhra Petrochemicals Ltd  ...                          NaN\n",
              "2            Force Motors Ltd  ...                          NaN\n",
              "3  Diamines And Chemicals Ltd  ...                          NaN\n",
              "4                 Insilco Ltd  ...                          NaN\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv0r_uh58Cfs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SonIp4OrOyg4",
        "outputId": "d0d7f36e-896f-4b54-dbcf-72a476ea320f"
      },
      "source": [
        "# Create a Dataset of Graphs to predict labels\n",
        "sample_data = SampleDataset(sample_set)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function dict.keys>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIhJzbTH6KQj",
        "outputId": "a3bfc817-7f7d-4d5c-c27c-0fa31ac3dd30"
      },
      "source": [
        "index_to_label = list(labels.keys())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "772"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1qMPjudzlsW"
      },
      "source": [
        "# Batch loader to run on the sample dataset to generate 5 most appropriate labellings\n",
        "loader_s = DisjointLoader(sample_data, batch_size=1, epochs=1)\n",
        "idx = 0\n",
        "for batch in loader_s:\n",
        "  inputs, target = batch\n",
        "  predictions = model(inputs, training=False).numpy()[0]\n",
        "  max_5 = []\n",
        "  for _ in range(5):\n",
        "    index = int(np.argmax(predictions, axis=-1))\n",
        "    max_5.append(index_to_label[index])\n",
        "    predictions[index] = -np.Inf\n",
        "  sample_set[\"Industry Classification Tags\"][idx] = str(max_5).strip(\"[]\")\n",
        "  idx += 1\n",
        "  \n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "eHkd_UUnDHkw",
        "outputId": "c9b0ea98-beaf-4a07-f154-cbfe9a1498d3"
      },
      "source": [
        "sample_set.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Business Description</th>\n",
              "      <th>Industry Classification Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3rd Rock Multimedia Ltd</td>\n",
              "      <td>3rd Rock Multimedia Limited is an India-based ...</td>\n",
              "      <td>'Application Software', 'Systems Software', 'R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Andhra Petrochemicals Ltd</td>\n",
              "      <td>The Andhra Petrochemicals Limited is an India-...</td>\n",
              "      <td>'Building Products', 'Diversified Support Serv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Force Motors Ltd</td>\n",
              "      <td>Force Motors Limited is a holding company. The...</td>\n",
              "      <td>'Integrated Telecommunication Services', 'Comm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Diamines And Chemicals Ltd</td>\n",
              "      <td>Diamines and Chemicals Limited is a holding co...</td>\n",
              "      <td>'Commodity Chemicals', 'Specialty Chemicals', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Insilco Ltd</td>\n",
              "      <td>Insilco Limited is engaged in manufacturing an...</td>\n",
              "      <td>'Research &amp; Consulting Services', 'Systems Sof...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Company   ...                       Industry Classification Tags\n",
              "0     3rd Rock Multimedia Ltd  ...  'Application Software', 'Systems Software', 'R...\n",
              "1   Andhra Petrochemicals Ltd  ...  'Building Products', 'Diversified Support Serv...\n",
              "2            Force Motors Ltd  ...  'Integrated Telecommunication Services', 'Comm...\n",
              "3  Diamines And Chemicals Ltd  ...  'Commodity Chemicals', 'Specialty Chemicals', ...\n",
              "4                 Insilco Ltd  ...  'Research & Consulting Services', 'Systems Sof...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4FC7JeIZD_g0",
        "outputId": "19470c9b-eaf5-4dc6-be69-b0ac2abe3676"
      },
      "source": [
        "# Download the processed test file\n",
        "sample_set.to_csv(\"Processed_file.csv\")\n",
        "from google.colab import files\n",
        "files.download(\"Processed_file.csv\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_69855078-6ab7-44b9-ad79-c80f565cda92\", \"Processed_file.csv\", 786431)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrgDVvVLXduJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}